{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\allis\\\\personal-site\\\\src\\\\pages\\\\Colombia.js\";\nimport React from \"react\";\nimport PageHead from \"../components/PageHead\";\nexport default function Colombia() {\n  return /*#__PURE__*/React.createElement(\"div\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 6,\n      columnNumber: 5\n    }\n  }, /*#__PURE__*/React.createElement(PageHead, {\n    name: \"Colombia Digital History Lab\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 7,\n      columnNumber: 9\n    }\n  }), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"page--body\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 8,\n      columnNumber: 9\n    }\n  }, /*#__PURE__*/React.createElement(\"h2\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 9,\n      columnNumber: 13\n    }\n  }, \"Intro\"), /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 10,\n      columnNumber: 13\n    }\n  }, \"The broader goal of the Colombia Digital History Lab (CDHL) is to create and compile public history products for scholars of Latin America, with an aim to make historical data more accessible. In the works is the Oligarchy Project, which maps the social networks of Colombian elites according to their self-identification in the \", /*#__PURE__*/React.createElement(\"i\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 12,\n      columnNumber: 153\n    }\n  }, \"Qui\\xE9n es qui\\xE9n (Who's who)\"), \" publication.\"), /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 14,\n      columnNumber: 13\n    }\n  }, \"The project that I'm currently working on is the Colombia Periodical Licenses Map. Professor Robert Karl had accumulated years and years of images from annual editions of Memorias del Ministerio del Gobierno, which list all of the years' registered newspaper licenses, typically formatted like that in Figure 1.\"), /*#__PURE__*/React.createElement(\"figure\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 18,\n      columnNumber: 13\n    }\n  }, /*#__PURE__*/React.createElement(\"img\", {\n    src: \"\",\n    alt: \"Sample of periodical license data\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 19,\n      columnNumber: 17\n    }\n  }), /*#__PURE__*/React.createElement(\"figcaption\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 20,\n      columnNumber: 17\n    }\n  }, \"Figure 1: Sample of periodical license data\")), /*#__PURE__*/React.createElement(\"h2\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 22,\n      columnNumber: 13\n    }\n  }, \"Data processing\"), /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 23,\n      columnNumber: 13\n    }\n  }, \"The first step in this project is extracting the text from these images. The most straightforward way to do this is by manually transcribing all of the information, of course, but that gets boring quickly. Optical Character Recognition (OCR) algorithms are able to \\\"read\\\" the text from images and process them as digital text. I had some familiarity with Google's Tesseract OCR engine and tried to use it on the data, but immediately ran into some issues. Figure 2 shows the image that I gave to the algorithm and what I got out of it.\"), /*#__PURE__*/React.createElement(\"figure\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 30,\n      columnNumber: 13\n    }\n  }, /*#__PURE__*/React.createElement(\"img\", {\n    src: \"\",\n    alt: \"Input data\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 31,\n      columnNumber: 17\n    }\n  }), /*#__PURE__*/React.createElement(\"img\", {\n    src: \"\",\n    alt: \"Output data\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 32,\n      columnNumber: 17\n    }\n  }), /*#__PURE__*/React.createElement(\"figcaption\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 33,\n      columnNumber: 17\n    }\n  }, \"Figure 2: Input image data and output text data\")), /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 35,\n      columnNumber: 13\n    }\n  }, \"Now, OCR is usually pretty messy, because computers aren't very good at doing human tasks, but this is very, very bad. After much trial and error, I realized that the problem is the long trail of periods after every word in the table: they're being read as letters for some reason, and it's ruining everything. When I removed them and made the images black and white, things worked much better (Figure 3).\"), /*#__PURE__*/React.createElement(\"figure\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 40,\n      columnNumber: 13\n    }\n  }, /*#__PURE__*/React.createElement(\"img\", {\n    src: \"\",\n    alt: \"Input data with periods removed\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 41,\n      columnNumber: 21\n    }\n  }), /*#__PURE__*/React.createElement(\"img\", {\n    src: \"\",\n    alt: \"Binarized (black and white) data\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 43,\n      columnNumber: 21\n    }\n  }), /*#__PURE__*/React.createElement(\"img\", {\n    src: \"\",\n    alt: \"Improved OCR Output\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 45,\n      columnNumber: 21\n    }\n  }), /*#__PURE__*/React.createElement(\"figcaption\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 46,\n      columnNumber: 21\n    }\n  }, \"Figure 3: Improved OCR Output after image processing\")), /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 48,\n      columnNumber: 13\n    }\n  }, \"Even after this, there are still some errors. Some of these can be caught with algorithms, but working with language is difficult, and there are lots of exceptions. Surely, there are more powerful spell-check resources that are able to fix these errors, but I didn't have access to these. Here comes the central tradeoff when it comes to data cleaning: accuracy vs. speed. If I spent ages, I could catch every error manually. However, my time might better be used elsewhere if I can accept a certain degree of data messiness. In this case, however, I'm creating a translation of an archival resource, where users will be approaching the product as something close or equivalent to the primary source. To avoid misleading information, it was important that I strive for accuracy, so I did spend extra time making sure the data was as clean as possible.\")), /*#__PURE__*/React.createElement(\"figure\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 61,\n      columnNumber: 13\n    }\n  }, /*#__PURE__*/React.createElement(\"img\", {\n    src: \"\",\n    alt: \"\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 62,\n      columnNumber: 21\n    }\n  }), /*#__PURE__*/React.createElement(\"figcaption\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 63,\n      columnNumber: 21\n    }\n  })));\n}","map":{"version":3,"names":["React","PageHead","Colombia"],"sources":["C:/Users/allis/personal-site/src/pages/Colombia.js"],"sourcesContent":["import React from \"react\"\r\nimport PageHead from \"../components/PageHead\"\r\n\r\nexport default function Colombia() {\r\n    return (\r\n    <div>\r\n        <PageHead name=\"Colombia Digital History Lab\" />\r\n        <div className=\"page--body\">\r\n            <h2>Intro</h2>\r\n            <p>\r\n                The broader goal of the Colombia Digital History Lab (CDHL) is to create and compile public history products for scholars of Latin America, with an aim to make historical data more accessible. \r\n                In the works is the Oligarchy Project, which maps the social networks of Colombian elites according to their self-identification in the <i>Quién es quién (Who's who)</i> publication.\r\n            </p>\r\n            <p>\r\n                The project that I'm currently working on is the Colombia Periodical Licenses Map. \r\n                Professor Robert Karl had accumulated years and years of images from annual editions of Memorias del Ministerio del Gobierno, which list all of the years' registered newspaper licenses, typically formatted like that in Figure 1.\r\n            </p>\r\n            <figure>\r\n                <img src=\"\" alt=\"Sample of periodical license data\" />\r\n                <figcaption>Figure 1: Sample of periodical license data</figcaption>\r\n            </figure>\r\n            <h2>Data processing</h2>\r\n            <p>\r\n                The first step in this project is extracting the text from these images. \r\n                The most straightforward way to do this is by manually transcribing all of the information, of course, but that gets boring quickly. \r\n                Optical Character Recognition (OCR) algorithms are able to \"read\" the text from images and process them as digital text. \r\n                I had some familiarity with Google's Tesseract OCR engine and tried to use it on the data, but immediately ran into some issues. \r\n                Figure 2 shows the image that I gave to the algorithm and what I got out of it.\r\n            </p>\r\n            <figure>\r\n                <img src=\"\" alt=\"Input data\" />\r\n                <img src=\"\" alt=\"Output data\" />\r\n                <figcaption>Figure 2: Input image data and output text data</figcaption>\r\n            </figure>\r\n            <p>\r\n                Now, OCR is usually pretty messy, because computers aren't very good at doing human tasks, but this is very, very bad. \r\n                After much trial and error, I realized that the problem is the long trail of periods after every word in the table: they're being read as letters for some reason, and it's ruining everything. \r\n                When I removed them and made the images black and white, things worked much better (Figure 3).\r\n            </p>\r\n            <figure>\r\n                    <img src=\"\" alt=\"Input data with periods removed\" />\r\n                    {/* <figcaption>Input image with periods removed</figcaption> */}\r\n                    <img src=\"\" alt=\"Binarized (black and white) data\" />\r\n                    {/* <figcaption>Binarized (black and white) image</figcaption> */}\r\n                    <img src=\"\" alt=\"Improved OCR Output\" />\r\n                    <figcaption>Figure 3: Improved OCR Output after image processing</figcaption>\r\n            </figure>\r\n            <p>\r\n                Even after this, there are still some errors.\r\n                Some of these can be caught with algorithms, but working with language is difficult, and there are lots of exceptions.\r\n                Surely, there are more powerful spell-check resources that are able to fix these errors, but I didn't have access to these.\r\n                Here comes the central tradeoff when it comes to data cleaning: accuracy vs. speed.\r\n                If I spent ages, I could catch every error manually.\r\n                However, my time might better be used elsewhere if I can accept a certain degree of data messiness.\r\n                In this case, however, I'm creating a translation of an archival resource, where users will be approaching the product as something close or equivalent to the primary source.\r\n                To avoid misleading information, it was important that I strive for accuracy, so I did spend extra time making sure the data was as clean as possible.\r\n\r\n            </p>\r\n            \r\n        </div>\r\n            <figure>\r\n                    <img src=\"\" alt=\"\" />\r\n                    <figcaption></figcaption>\r\n            </figure>\r\n    </div>\r\n    )\r\n}"],"mappings":";AAAA,OAAOA,KAAK,MAAM,OAAO;AACzB,OAAOC,QAAQ,MAAM,wBAAwB;AAE7C,eAAe,SAASC,QAAQ,GAAG;EAC/B,oBACA;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,gBACI,oBAAC,QAAQ;IAAC,IAAI,EAAC,8BAA8B;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,EAAG,eAChD;IAAK,SAAS,EAAC,YAAY;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,gBACvB;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,GAAI,OAAK,CAAK,eACd;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,GAAG,2UAEyI;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,GAAG,kCAA0B,CAAI,iBAC7K,CAAI,eACJ;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,GAAG,yTAGH,CAAI,eACJ;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,gBACI;IAAK,GAAG,EAAC,EAAE;IAAC,GAAG,EAAC,mCAAmC;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,EAAG,eACtD;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,GAAY,6CAA2C,CAAa,CAC/D,eACT;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,GAAI,iBAAe,CAAK,eACxB;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,GAAG,2hBAMH,CAAI,eACJ;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,gBACI;IAAK,GAAG,EAAC,EAAE;IAAC,GAAG,EAAC,YAAY;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,EAAG,eAC/B;IAAK,GAAG,EAAC,EAAE;IAAC,GAAG,EAAC,aAAa;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,EAAG,eAChC;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,GAAY,iDAA+C,CAAa,CACnE,eACT;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,GAAG,uZAIH,CAAI,eACJ;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,gBACQ;IAAK,GAAG,EAAC,EAAE;IAAC,GAAG,EAAC,iCAAiC;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,EAAG,eAEpD;IAAK,GAAG,EAAC,EAAE;IAAC,GAAG,EAAC,kCAAkC;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,EAAG,eAErD;IAAK,GAAG,EAAC,EAAE;IAAC,GAAG,EAAC,qBAAqB;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,EAAG,eACxC;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,GAAY,sDAAoD,CAAa,CAC5E,eACT;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,GAAG,q1BAUH,CAAI,CAEF,eACF;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,gBACQ;IAAK,GAAG,EAAC,EAAE;IAAC,GAAG,EAAC,EAAE;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,EAAG,eACrB;IAAA;IAAA;MAAA;MAAA;MAAA;IAAA;EAAA,EAAyB,CACxB,CACX;AAEV"},"metadata":{},"sourceType":"module"}